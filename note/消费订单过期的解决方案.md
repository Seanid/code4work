# 消费订单过期的解决方案

消费订单过期的业务场景，其实是比较常见的数据延迟处理常见，顺推可以发现很多相似的场景，如自动收货、消息延期推送等。

这一类的解决方案存在很多种，大致可以分为以下几种：
* 触发式（不推荐）：即当数据再次被查询的时候，根据查询的时间点，触发是否执行的业务逻辑。
  * 缺点：
    * 这种方式，可能导致大量脏数据没法被处理
    * 此类逻辑要求客户对数据过期这一事件非常不敏感，否则就会导致事件延迟严重，最终给用户带来不好的体验。消费订单通常还包含着优惠券、运费险等诸多附加业务逻辑，**所以这种方式，相当不推荐**。
    * 查询时候的写操作，会给系统带来一定的压力
  * 方案：
    * 数据查询时在代码层次触发延迟逻辑，压力在代码+数据库（不推荐）
    * 数据库查询或者更新时通过数据库触发器触发，压力在数据库（不推荐）
* 延迟队列（建议根据业务酌情处理）：通过延迟队列的方式，将消息放入队列，待达到延迟效果触发消费者进行消费
  * 缺点:
    * 数据冗余多了一份，在数据量大的情况下，会给队列带来极大的压力
    * 采用队列模式，数据状态修改的时候，没法对队列中的数据实现修改，最后可能导致大量的无效数据
    * 队列模式存在数据丢失的情况
  * 方案：
    * 内存队列（Java的DelayQueue，Netty的时间轮等，只适合与单机使用，不推荐）
    * Rabbitmq的死信队列（包括插件模式）
    * RocketMq的延迟队列
    * Redis的失效事件监听
    * Redis的zset（将时间戳作为score，通过扫描实现数据的筛选，但在分布式情况下会导致数据的重复读取，需要在逻辑上做好幂等操作。同样的逻辑，redisson也有一套解决方案，解决了重复读取问题）
* 调度轮询（推荐）：通过任务调度的东西定时扫描，并对数据进行处理，这种方案适合一些对时间要求不高的场景
  * 缺点：
    * 由于是定时调度，时间准确度没法做到很精细
    * 调度扫描的是数据库表，数据量大的情况下，会给数据库带来压力，需要做好读写分离。同时，如果存在分表分库的情况，还需要做好多表扫描的逻辑处理
    * 任务粒度，将会影响到数据的处理速度，最后影响数据延迟的问题
  * 方案：
    * xxl-job
    * DolphinScheduler

以上的解决方案，从技术角度出发，通过额外的调度系统实现消费订单的过期是最推荐的。但是在现实环境中，并非所有的系统对延迟的容忍度都那么高，所以其实在生产环境中使用MQ解决方案的也不在少数。
 